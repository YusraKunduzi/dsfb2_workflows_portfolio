[["index.html", "verander strakjes 1 Introduction", " verander strakjes Yusra Kunduzi 2025-01-09 1 Introduction Welcome to my GitHub Pages portfolio! This portfolio is created based on assignments from the Data Science Workflows course and projects from the minor in Data Science for Biology. In this portfolio, you can find a variety of things I’ve learned and created, such as an R package and examples of my usual work in RStudio. Additionally, I’ve completed a mini project using Python, expanding my skill set beyond R. Each project demonstrates the techniques I’ve applied and the workflows I’ve developed, showcasing my growth in data science. "],["curriculum-vitae---yusra-kunduzi.html", "2 Curriculum Vitae - Yusra Kunduzi", " 2 Curriculum Vitae - Yusra Kunduzi Figure 1: Curriculum Vitae. "],["het-effect-van-transposons-op-biologische-processen-van-de-e.-coli.html", "3 Het effect van transposons op biologische processen van de E. coli", " 3 Het effect van transposons op biologische processen van de E. coli Voor mijn vrije opdracht wil ik het effect van transposons op bacteriën onderzoeken. Aangezien mijn afstudeerrichting microbiologie is, sluit dit onderwerp er goed bij aan. De ruwe data die ik zal gebruiken komt van GEO, onder de accession GSE197084. In dit onderzoek werd het effect van transposons op de virulentie van Escherichia coli bestudeerd. Het genoom van E. coli werd eerst gesequenced, waarna transposons werden geïntroduceerd. De gemuteerde bacteriën werden vervolgens geïmplanteerd in de hersenen, milt en longen van muizen om de effecten van de gemuteerde bacteriën in verschillende omgevingen te bestuderen. Na de infectie werden de bacteriën opnieuw gesequenced. Mijn doel is om de data van de E. coli voor en na transposon-insertie te vergelijken en een bredere analyse te maken van de genen en biologische processen die mogelijk zijn beïnvloed door de transposons. Ik ben niet alleen geïnteresseerd in virulentie-gerelateerde genen, maar wil ook onderzoeken hoe andere genetische processen mogelijk zijn aangepast door de transposons. Voor de analyse zal ik ongeveer dezelfde workflow gebruiken als in DAUR2. Ik zal de analyse volledig uitvoeren in Python en daarbij ook andere technieken gebruiken, zoals BWA i.p.v. Bowtie2 of Rsubread, en Sambamba i.p.v. Rsamtools. Door deze tools te gebruiken, kan ik de analyse in een andere programmeertaal uitvoeren en tegelijkertijd de methoden en concepten die ik tijdens de cursus heb geleerd toepassen. "],["looking-ahead.html", "4 Looking ahead", " 4 Looking ahead Where do I want to be in ~2 years time? In two years time i expect myself to be recently graduated from Hogeschool Utrecht (Life Science). I will work at a company focused on research within the life sciences, specifically in a department that specializes in microbiological research, where I am also able to apply my data science skills. I expect to be more confident in my data science and researching skills. Looking even further ahead, I plan on leading research projects in my field and publish my findings to contribute to the scientific community. . How am I doing now with respect to this goal? I’m well on my way to achieving my goals. Sometimes, I don’t fully realize how much I’ve learned over the past few years, but I often surprise myself when I excel at my work. I’m currently focusing on enhancing my data science skills and I will begin my research internship in February, which is the final phase of my studies before graduation. What would be the next skill to learn? One skill I’m excited to develop is working in larger teams after I graduate. Although I’ve had experience working in smaller groups, which has gone well, I look forward to collaborating with a larger team and learning how to navigate that dynamic effectively. "],["guerrilla-analytics-on-daur2-course.html", "5 Guerrilla Analytics on DAUR2 course", " 5 Guerrilla Analytics on DAUR2 course Guerrilla analytics is an approach to data management and analysis that focuses on efficiency, simplicity, and speed. It prioritizes creating practical workflows and making fast, effective choices with the available resources. For my DAUR2 RNA sequencing and metagenomics assignments, I applied guerrilla analytics by reorganizing my project structure to optimize data management. I focused on keeping essential files well-organized, removed unnecessary large datasets, and provided clear documentation in readme.txt files. I visualized the folder structure using the {fs} package in R, as shown in the figure below, to make the project more organized and easier to navigate. Figure 2: Directory tree of the DAUR2 course. "],["c.-elegans-plate-experiment.html", "6 C. elegans plate experiment 6.1 Analyzing the data", " 6 C. elegans plate experiment In this experiment, C. elegans nematodes were exposed to varying concentrations of different compounds. The dataset, provided by J. Louter, includes key variables such as the number of offspring (RawData), compound names (compName), concentrations (compConcentration), and experimental types (expType). The aim of the analysis was to create visualizations using ggplot2 and outline the steps for performing a dose-response analysis to assess the relationship between compound concentrations and offspring count. #change compName and expType into factors flow_tidy$compName &lt;- as.factor(flow_tidy$compName) flow_tidy$expType &lt;- as.factor(flow_tidy$expType) #change compConcentration into numeric column flow_tidy$compConcentration &lt;- as.numeric(flow_tidy$compConcentration) #remove rows with NA in RawData flow_tidy &lt;- flow_tidy %&gt;% filter(!is.na(RawData)) #mean of controlNegative for normalization of data control_negative_mean &lt;- mean(flow_tidy$RawData[flow_tidy$expType == &quot;controlNegative&quot;], na.rm = TRUE) #new column with normalized data (normalized to the controlNegative mean) flow_tidy &lt;- flow_tidy %&gt;% mutate(NormalizedData = RawData / control_negative_mean) #take the log10 value of compConcentration flow_tidy$logConcentration &lt;- log10(flow_tidy$compConcentration) #plot the data with jitter to avoid overlapping points and color by compName flow_tidy_plot &lt;- flow_tidy %&gt;% ggplot(aes(x = logConcentration, y = NormalizedData, colour = compName, shape = expType)) + geom_jitter(width = 0.1, height = 0.1) + theme_bw() + labs( title = &quot;C.elegans Nematodes Exposed to Varying Concentrations of Different Compounds&quot;, x = &quot;Log10 of the Concentration in nM&quot;, y = &quot;Normalized Offspring Count&quot; ) print(flow_tidy_plot) Figure 3: Scatterplot showing the effect of different compounds at various concentrations on C. elegans offspring The concentration of the compounds have a wide range, which isn’t ideal for visualization in the scatterplot. To solve this, the log10 value of compConcentration is used, reducing the distance between data points. Another issue is that compConcentration being of the class ‘character’ disrupts the order in which the data is displayed. RawData is of class ‘numeric’, which is correct. compName and expType were both initially of class ‘character’ and have been changed to ‘factor’. compConcentration was of class ‘character’, but changed to ‘numeric’. The positive control for this experiment is Ethanol. The negative control for this experiment is S-medium. Normalizing the data gives a baseline for comparison, reducing variability. This makes it easier to spot meaningful differences by ensuring that any changes are due to the experimental conditions, not just natural differences in the data. 6.1 Analyzing the data If this experiment is analyzed to determine if there is an effect of different concentrations on offspring count and whether the compounds have varying effects, the following steps should be followed: 1: Preparation of the Data: First, the data should be imported from the Excel file into RStudio to prepare it for analysis. During this process, columns should be assigned the correct data types, NA values should be removed, and the data should be normalized. Specifically, normalization should ensure that the mean value of the negative control is equal to 1, with all other values expressed as fractions of the negative control. This step is essential for comparing the effects of different compounds consistently. 2: Visualization of the Data with a Scatterplot: This step is important for identifying potential issues with the data and making any necessary adjustments. It allows you to visualize the relationship between compound concentrations and offspring count. Use the compound concentration on the X-axis and the offspring count (RawData) on the Y-axis, with different colors representing each compound and different shapes representing the experimental types. Jitter can be applied to prevent overlapping data points. 3: Dose-Response Curve (DRC): To better analyze the effects of the compounds on C. elegans and assess the relationship between dose and response, a DRC is necessary. This involves fitting a dose-response model using the {drc} package in R. Use the log-transformed compound concentration on the X-axis and the offspring count (RawData) on the Y-axis. The DRC will help quantify key parameters such as the IC50 value, as well as the minimal and maximal response levels. 4: Analysis/Conclusion of the DRC: The analysis should focus on determining the IC50 value for each compound, identifying the minimal and maximal concentrations affecting C. elegans, and comparing the dose-response curves to evaluate differences in compound effects. Controls should be used to validate the experimental results. titel en auteur erbij? "],["review-and-reproducibility.html", "7 Review and Reproducibility 7.1 Open Peer Review 7.2 Reprocudibility assessment", " 7 Review and Reproducibility 7.1 Open Peer Review SARS-CoV-2 variants reveal features critical for replication in primary human cells Since the emergence of the COVID-19 virus and the millions of people it infected, the amount of research on it has increased. Part of this research focuses on genome sequencing to identify various variants, but there has been limited research on how these mutations affect processes like virus replication or transmission. This article presents research on 14 different SARS-CoV-2 variants that emerged during the early stages of the pandemic in Europe. The goal of this research was to gain a better understanding of these variants. To achieve this, the variants were isolated from anonymized patient samples collected in Switzerland between March and May 2020. These samples were cultured in Vero-CCL81 cells, and primary bronchial epithelial cells (BEpCs) from three different human donors were also used to grow the variants. The virus was cultured through multiple passages in Vero-CCL81 cells to generate viral stocks. The viral growth, genetic variants, and specific mutations, such as those in the Spike protein and other genes, were analyzed using sequencing and phenotypic assays. The full genome sequencing was performed using next-generation sequencing (NGS) methods. The results showed that certain mutations, such as the D614G substitution in the Spike protein, were associated with enhanced replication in human cells. Additionally, mutations that occurred during passage in Vero cells, such as deletions in the furin cleavage site, strongly affected replication in BEpCs. This highlights the importance of carefully checking viral stocks when studying new variants. Statistical significance was determined using one-way ANOVA and unpaired t-tests on log2-transformed data. The research was conducted in a BSL3 facility, with all procedures, including risk assessments and protective measures, approved by the Swiss Federal Office of Public Health. All relevant data are available through GISAID (accession IDs EPI_ISL_590823 to EPI_ISL_590836). Although the article does not provide specific information on the availability of the code used, it offers extensive methodological details and transparency in the results. (pohlSARSCoV2VariantsReveal2021?) (#tab:peer review)Peer Review Transparency Criteria Table Transparency.Criteria Definition Response.Type Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Yes Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a study’s data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Yes Data Location Where the article’s data can be accessed, either raw or processed. All SARS-CoV-2 isolate sequences are available from GISAID (accession IDs EPI_ISL_590823 to EPI_ISL_590836) Study Location Author has stated in the methods section where the study took place or the data’s country/region of origin. Yes; Switzerland (Zurich) Author Review The professionalism of the contact information that the author has provided in the manuscript. E-mail addresses for multiple autors are provided Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. No Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Yes Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. No 7.2 Reprocudibility assessment Reproducibility in research is necessary as it allows other researchers to use the data and code for their own work. Unfortunately, the data or code isn’t always accessible, sometimes hindering progress. Even when both are available, it’s important to assess whether the code is truly reproducible. This is why I reviewed a paper titled “Effect of Targeted Behavioral Science Messages on COVID-19 Vaccination Registration Among Employees of a Large Health System” on PubMed. The code and data for this study were available on OSF, with one file for the scripts and three files for the data. After reviewing the code, I would rate its readability a 3/5. While the code is not bad, it could be clearer. Some variable names were understandable, but as the number of variables increased, they became less clear. The code could also benefit from more consistent comments. The reproducibility of the code is a 5/5. The three lines for importing the data, with placeholders for file paths like “INSERT PATH HERE” were clear. After inserting my own file paths, the code ran without issues, generating a bar chart identical to the one in the paper. The code first loads the datasets, then summarizes key variables like registration numbers, email opens, clicks, and deliveries. After preparing and cleaning the data, it generates three bar charts for visualisation. library(dplyr) library(psych) library(gmodels) library(zoo) ## for working with dates library(chron) ##for working with dates library(ggplot2) library(effects) ## for CI library(DT) ## for tables library(RColorBrewer) ## for survey plot VAC.SURVEY.PATH &lt;- &quot;C:/Users/yusra/OneDrive/Documenten/dsfb2_workflows_portfolio/ruwe_data/COVID_Vaccine_Employee_Survey_20210202_OSF.csv&quot; VAC.SURVEY &lt;- read.csv(gsub(&quot;[\\r\\n]&quot;, &quot;&quot;, VAC.SURVEY.PATH), header = TRUE, na.strings = c(&quot;&quot;, &quot;N/A&quot;, &quot;NA&quot;)) total &lt;- nrow(VAC.SURVEY) freq_table &lt;- data.frame(table(VAC.SURVEY$main)) names(freq_table) &lt;- c(&quot;Codes&quot;, &quot;Freq&quot;) tmp &lt;- freq_table %&gt;% arrange(Freq) freq_table$Codes &lt;- factor(freq_table$Codes, levels = tmp$Codes) freq_table$Perc &lt;- paste(round((freq_table$Freq/total)*100,1), &quot;%&quot;, sep = &quot;&quot;) ggplot(freq_table, aes(x = Codes, y = Freq, fill = Codes)) + geom_bar(stat = &#39;identity&#39;, position = position_dodge(), color = &#39;black&#39;) + theme_classic() + theme(axis.text.x = element_text(vjust = 1, hjust = 1), axis.text = element_text(size = 7, color = &#39;black&#39;), strip.text = element_text(size = 7), axis.title = element_text(size = 7), axis.title.y = element_text(margin = unit(c(5, 0, 0, 0, 0), &quot;mm&quot;)), legend.position = &#39;none&#39;) + xlab(&quot;&quot;) + ylab(&quot;\\nNumber of respondents&quot;) + geom_text(aes(label=Perc), size=3, position=position_dodge(width=0.9), hjust=-0.2, color=&#39;black&#39;) + scale_fill_manual(values = c(&#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &#39;white&#39;, &quot;#1B7837&quot;, &quot;#5AAE61&quot;, &quot;#A6DBA0&quot;, &quot;#D9F0D3&quot;, &quot;#F7F7F7&quot;, &quot;#E7D4E8&quot;, &quot;#C2A5CF&quot;, &quot;#9970AB&quot;, &quot;#762A83&quot;)) + coord_flip() + ylim(c(0, max(freq_table$Freq)*1.3)) Figure X: titel en bijschrift "],["new-rpackage.html", "8 New Rpackage", " 8 New Rpackage text.analyzer Package The text.analyzer package simplifies text analysis in R. It provides a set of functions to quickly analyze text data, such as word and sentence counts, identifying the longest word, and extracting the most frequent words. The package is designed to be efficient, allowing users to perform basic text analysis tasks without the need for complex setups. Development of the text.analyzer Package I started developing the text.analyzer package by creating a new R package project with devtools::create_package(). This automatically set up the file structure and made the project ready to use in RStudio. The first function I added was text_summary(), which summarizes text data. I documented it using roxygen2 and ran devtools::check() to fix any issues. After that, I added more functions, like longest_word(), top10_words(), and sentence_summary(), following the same process: writing the function, documenting it, testing it, and fixing any problems. Once the package was complete, I installed it locally with devtools::install() to make sure everything worked as expected. I also created a vignette in RMarkdown, placed it in the vignettes/ folder, and built it using devtools::build_vignettes(). This made the vignette accessible through browseVignettes(). Finally, I uploaded the package to GitHub, set up continuous integration, and added a README.md file with installation instructions and examples to help users get started. Installing text.analyzer # Install using devtools devtools::install_github(&quot;YusraKunduzi/text.analyzer&quot;) # Install using pak (preferred for dependency management) pak::pak(&quot;YusraKunduzi/text.analyzer&quot;) Usage library(text.analyzer) #Example text, the first paragraph of this page text &lt;- &quot;The text.analyzer package simplifies text analysis in R. It provides a set of functions to quickly analyze text data, such as word and sentence counts, identifying the longest word, and extracting the most frequent words. The package is designed to be efficient, allowing users to perform basic text analysis tasks without the need for complex setups.&quot; #How to use text_summary sum &lt;- text_summary(text) print(sum) ## $word_count ## [1] 56 ## ## $sentence_count ## [1] 4 ## ## $average_word_length ## [1] 5.285714 ## ## attr(,&quot;class&quot;) ## [1] &quot;text_summary&quot; #How to use longest_word longest &lt;- longest_word(text) print(longest) ## $word ## [1] &quot;text.analyzer&quot; ## ## $length ## [1] 13 ## ## $position ## $position$line ## [1] 1 ## ## $position$index ## [1] 2 #How to use top10_words top &lt;- top10_words(text) print(top) ## words Freq ## 1 text 3 ## 2 to 3 ## 3 analysis 2 ## 4 package 2 ## 5 word 2 ## 6 allowing 1 ## 7 analyze 1 ## 8 as 1 ## 9 basic 1 ## 10 be 1 #How to use sentence_summary sentences &lt;- sentence_summary(text) print(sentences) ## $sentence_count ## [1] 4 ## ## $avg_sentence_length ## [1] 14.25 ## ## $longest_sentence ## [1] &quot; It provides a set of functions to quickly analyze text data, such as word and sentence counts, identifying the longest word, and extracting the most frequent words&quot; ## ## $shortest_sentence ## [1] &quot;The text&quot; ## ## $readability_score ## [1] -254.8002 ## ## attr(,&quot;class&quot;) ## [1] &quot;sentence_summary&quot; "],["project---rshiny-app.html", "9 Project - Rshiny app", " 9 Project - Rshiny app Bacteria Analysis Board for VITEK® MS The VITEK MS is a machine commonly used in clinical microbiology for the identification of yeasts, bacteria, and their antibiotic resistance or sensitivity. This mass spectrometry system utilizes biochemical tests to distinguish between bacterial species based on their distinct responses to a series of chemical reactions (De Respinis et al. 2014). The process begins by inserting a bacterial solution along with an identification or antibiotics card into the VITEK MS system. Each card contains a set of biochemical tests specific to the bacteria being analyzed. As the bacterial solution is drawn through the card, the system measures the extinction values corresponding to each test, indicating the bacteria’s reaction to the biochemical compounds. Each species has a unique pattern of extinction values, allowing the VITEK MS to accurately identify them based on their specific response patterns. While the VITEK MS is efficient and has a large database for identifying a wide range of organisms, it does have limitations (Okabe et al. 2000). One of the main challenges is distinguishing closely related bacterial species that exhibit similar biochemical response patterns. For example, Streptococcus mitis and Streptococcus oralis, both Gram-positive bacteria, are often difficult to differentiate using the VITEK system alone. Their biochemical reaction patterns are so similar that the system frequently produces a combined result, indicating both species are present, rather than providing a definitive identification. This issue also occurs with the MALDI-TOF MS system, which, despite its large database, struggles to differentiate between these closely related species due to their highly similar protein profiles (Han, Jeong, and Choi 2021). Our project aims to address this limitation by investigating the differences in extinction patterns between S. mitis and S. oralis using the VITEK MS data. Through detailed analysis of the extinction outcomes from the biochemical tests on the Gram-positive cards, we aim to identify even the slightest differences between these two species. By leveraging advanced data analysis techniques, we will develop an application or website where users can input their VITEK extinction data files. These files will then be processed through custom scripts that allow users to visualize and interpret the data more effectively. The core functionality of the Rshiny app will include the ability to generate visualizations such as scatterplots, boxplots, heatmaps, and Principal Component Analysis (PCA) plots (Leong et al. 2020). These tools will help users better understand how their samples compare across different tests. The primary goal is to provide a more accurate and detailed view of the subtle differences between closely related bacteria like S. mitis and S. oralis. For instance, scatterplots will allow users to see how individual tests correlate, while heatmaps will highlight patterns of bacterial response across all tests. PCA plots will help users observe the overall distribution of their samples, making it easier to spot any clustering or outliers that may indicate different bacterial species. Already, some differences have been observed in the extinction patterns of certain tests between S. mitis and S. oralis. These findings have led to the development of a new feature for the Rshiny app: a Mitis/Oralis Checker. This tool will allow users to input their VITEK data and receive a more straightforward answer regarding whether they are dealing with S. mitis or S. oralis. The checker will be based on the identified patterns from the biochemical tests and will use the data from the visualizations as a reference. While the checker provides a quick and user-friendly solution, users will still have the option to view the detailed plots and analyses to understand the basis of the checker’s conclusions. For now, the app will support any bacteria tested with the Gram-positive card, ensuring that a wide range of samples can be analyzed. This tool has the potential to improve bacterial identification accuracy in clinical microbiology by providing more precise results, especially in cases where traditional systems like the VITEK MS may fall short. Ultimately, our project aims to enhance the ability to distinguish between similar bacterial species. Because the Rshiny app is already set up for Gram-positive identification cards, adding the information and tests for a Gram-negative card would not be difficult (Wallet et al. 2005). Researching and obtaining data from other bacteria that are difficult to distinguish would be helpful in developing additional checkers, like the Mitis/Oralis checker. Although these additions would be valuable, they are outside the scope of the current project and could be explored in future projects. bibliography: My_Library.bib "],["references.html", "10 References", " 10 References De Respinis, Sophie, Valérie Monnin, Victoria Girard, Martin Welker, Maud Arsac, Béatrice Cellière, Géraldine Durand, et al. 2014. “Matrix-Assisted Laser Desorption Ionization–Time of Flight (MALDI-TOF) Mass Spectrometry Using the Vitek MS System for Rapid and Accurate Identification of Dermatophytes on Solid Cultures.” Edited by Y.-W. Tang. J Clin Microbiol 52 (12): 4286–92. https://doi.org/10.1128/JCM.02199-14. Han, Sang-Soo, Young-Su Jeong, and Sun-Kyung Choi. 2021. “Current Scenario and Challenges in the Direct Identification of Microorganisms Using MALDI TOF MS.” Microorganisms 9 (9): 1917. https://doi.org/10.3390/microorganisms9091917. Leong, Claudia, Jillian J Haszard, Anne-Louise M Heath, Gerald W Tannock, Blair Lawley, Sonya L Cameron, Ewa A Szymlek-Gay, et al. 2020. “Using Compositional Principal Component Analysis to Describe Children’s Gut Microbiota in Relation to Diet and Body Composition.” The American Journal of Clinical Nutrition 111 (1): 70–78. https://doi.org/10.1093/ajcn/nqz270. Okabe, Tadashi, Kozue Oana, Yoshiyuki Kawakami, Masaru Yamaguchi, Yuko Takahashi, Yukie Okimura, Takayuki Honda, and Tsutomu Katsuyama. 2000. “Limitations of Vitek GPS-418 Cards in Exact Detection of Vancomycin-Resistant Enterococci with the vanB Genotype.” J Clin Microbiol 38 (6): 2409–11. https://doi.org/10.1128/JCM.38.6.2409-2411.2000. Wallet, Frédéric, Caroline Loïez, Emilie Renaux, Nadine Lemaitre, and René J. Courcol. 2005. “Performances of VITEK 2 Colorimetric Cards for Identification of Gram-Positive and Gram-Negative Bacteria.” J Clin Microbiol 43 (9): 4402–6. https://doi.org/10.1128/JCM.43.9.4402-4406.2005. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
